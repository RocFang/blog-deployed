<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>shell on 纯真年代</title>
    <link>https://pureage.info/tags/shell/</link>
    <description>Recent content in shell on 纯真年代</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>2011-2020 strider. [CC-BY-4.0](https://creativecommons.org/licenses/by/4.0/deed.zh)</copyright>
    <lastBuildDate>Wed, 30 Apr 2014 15:43:00 +0000</lastBuildDate>
    
	<atom:link href="https://pureage.info/tags/shell/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>RPM中的%config和%config(noreplace)</title>
      <link>https://pureage.info/2014/04/30/noreplace-in-rpm-spec-file.html</link>
      <pubDate>Wed, 30 Apr 2014 15:43:00 +0000</pubDate>
      
      <guid>https://pureage.info/2014/04/30/noreplace-in-rpm-spec-file.html</guid>
      <description>&lt;p&gt;打开一个rpm spec文件，在 %files段有一个指令很常见：%config(noreplace)，这个指定到底是干什么用的呢？&lt;/p&gt;
&lt;p&gt;答案是，该指令决定如果一个文件被管理员修改过后，下次更新该文件所在的rpm包时，该文件的存在状态。例如，一般升级软件时，配置文件是不会变化的，而主程序则一般需要被升级（替换）。&lt;/p&gt;
&lt;p&gt;对于spec文件中在%files段的某一个文件，我们要讨论三种情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;没有带%config指令。例如：%{_sbindir}/redis-server&lt;/li&gt;
&lt;li&gt;带了%congfig指令。例如：%config %{_sysconfdir}/redis/redis.conf&lt;/li&gt;
&lt;li&gt;带了%config(noreplace)指令。例如：%config(noreplace) %{_sysconfdir}/redis/redis.conf&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>依赖一个RPM来制作新的RPM</title>
      <link>https://pureage.info/2014/01/27/176.html</link>
      <pubDate>Mon, 27 Jan 2014 03:41:46 +0000</pubDate>
      
      <guid>https://pureage.info/2014/01/27/176.html</guid>
      <description>&lt;p&gt;项目中有这样一个场景：A软件通过RPM包发布，B软件严重依赖A软件，但在它的基础上有一些业务逻辑的添加和修改。A软件是公司一个历史悠久的产品，且保持频繁的更新，B软件是我在维护。&lt;/p&gt;
&lt;p&gt;在开发的时候，很简单，先把某一个稳定版本的A软件安装到开发机上，然后直接进行业务逻辑的开发就可以了。但在发布的时候肯定就不能这么做了，你很难要求运维先去发布服务器上下载一个A软件的rpm包，安装或更新完后，再去发布服务器上下载一个B软件的业务逻辑包，再进行相关的配置。如果是一台机器就罢了，几十上百台服务器这样玩就是作死。所以，我需要做出一个B软件的独立的rpm包，用这个rpm包安装或更新后，直接能进行相关的配置。&lt;/p&gt;
&lt;p&gt;再来澄清一下需求：B软件既要严重依赖A软件，但要在A软件上添加很多业务逻辑。但要求在发布的时候脱离对A软件rpm包的依赖。&lt;/p&gt;
&lt;p&gt;最简单的方法，当然是先把A软件的代码库做一个分支，或者拷贝出一个新的代码库，在上面进行开发，将B软件与A软件独立开来。这样发布的时候当然就是一个独立的包了。但如前所属，A软件更新频繁，生命力旺盛，我可不想时时来在同步上花时间。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>利用here document携带c代码</title>
      <link>https://pureage.info/2013/10/08/129.html</link>
      <pubDate>Tue, 08 Oct 2013 03:23:00 +0000</pubDate>
      
      <guid>https://pureage.info/2013/10/08/129.html</guid>
      <description>&lt;p&gt;假设你想通过一段脚本调用make来编译代码，并且在脚本中将一些编译需要的系统信息传递给makefile，可以通过bash的here document来实现。例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tmp_src_filename=fdfs_check_bits.c  
cat &amp;lt;&amp;lt;EOF &amp;gt; $tmp_src_filename  
#include &amp;lt;stdio.h&amp;gt;  
#include &amp;lt;unistd.h&amp;gt;  
#include &amp;lt;fcntl.h&amp;gt;  
int main()  
{  
        printf(&amp;quot;%d\n&amp;quot;, (int)sizeof(long));  
        printf(&amp;quot;%d\n&amp;quot;, (int)sizeof(off_t));  
        return 0;  
}  
EOF  
  
gcc -D_FILE_OFFSET_BITS=64 -o a.out $tmp_src_filename  
output=$(./a.out)  
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>emlog的一键备份</title>
      <link>https://pureage.info/2013/10/01/128.html</link>
      <pubDate>Tue, 01 Oct 2013 03:31:00 +0000</pubDate>
      
      <guid>https://pureage.info/2013/10/01/128.html</guid>
      <description>&lt;p&gt;不知道大家平时备份是不是和我一样这么操作的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;登陆到后台，备份sql（当然，或者是用插件定期备份发送到邮箱）&lt;/li&gt;
&lt;li&gt;用ftp备份content目录&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果你想简化操作，并且和我一样苦逼的用着虚拟主机，下面的脚本也许可以帮到你。脚本很丑陋，能完成功能即可。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>漫谈logrotate与crond</title>
      <link>https://pureage.info/2013/09/10/127.html</link>
      <pubDate>Tue, 10 Sep 2013 15:11:00 +0000</pubDate>
      
      <guid>https://pureage.info/2013/09/10/127.html</guid>
      <description>&lt;h1 id=&#34;什么是logrotate&#34;&gt;什么是logrotate&lt;/h1&gt;
&lt;p&gt;logrotate是一款用来切割日志的工具，更确切的说，是切割文本的工具，但通常用在软件日志切割上。为什么要进行日志切割呢？原因可以有很多，最明显的一个就是防止日志文件变得太大。&lt;/p&gt;
&lt;h1 id=&#34;lorotate的切割方式&#34;&gt;lorotate的切割方式&lt;/h1&gt;
&lt;p&gt;以nginx为例，假设其错误日志放在/data/proclog/log/nginx/下，名为nginx_error.log,当logrotate运行时，如果满足切割要求了，则会将nginx_error.log改名为nginx_error.log.1,并重新创建一个新的空文件nginx_error.log作为新的错误日志。&lt;/p&gt;
&lt;p&gt;当进行其二次切割时，nginx_error.log.1被改名为nginx_error.log.2,刚才创建的nginx_error.log被改名为新的nginx_error.log.1,然后再次重新创建一个新的空文件nginx_error.log作为新的错误日志投入使用。&lt;/p&gt;
&lt;p&gt;当进行第三次切割时，nginx_error.log.2变为nginx_error.log.3,nginx_error.log.1变为nginx_error.log.2,nginx_error.log变为nginx_error.log.1,一个新的nginx_error.log被再次创建。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>uniq、sort不得不注意的尾部空格（trailing whitespaces)</title>
      <link>https://pureage.info/2013/09/09/126.html</link>
      <pubDate>Mon, 09 Sep 2013 13:38:00 +0000</pubDate>
      
      <guid>https://pureage.info/2013/09/09/126.html</guid>
      <description>&lt;h1 id=&#34;问题产生背景&#34;&gt;问题产生背景&lt;/h1&gt;
&lt;p&gt;自己写的一个基于FastDFS的客户端软件的日志格式如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[2013-09-06 08:57:01] 1884096 group6/M00/00/2D/Kj4ZKlIpKL6Actm8ABy_wPYwpa8782.mp3 ;fuckgfw.com/mp3k18/a2/1375_8767.mp3  
[2013-09-06 08:57:01] 1932032 group6/M00/00/2D/Kj4ZKlIpKL6APMlMAB17AFl-Zaw344.mp3 ;fuckgfw.com/mp3k18/a2/1390_20402.mp3
[2013-09-06 08:57:01] 2115392 group6/M00/00/28/Kj4ZK1IpKL6AUW6WACBHQHAveu0805.mp3 ;fuckgfw.com/mp3k18/a2/1381_8842.mp3  
[2013-09-06 08:57:01] 2340800 group6/M00/00/28/Kj4ZK1IpKL-ABGh8ACO3wLWZNXA955.mp3 ;fuckgfw.com/mp3k18/a2/1395_9009.mp3  
[2013-09-06 08:57:01] 1734272 group6/M00/00/28/Kj4ZK1IpKL-AZF8OABp2gDqh-sA949.mp3 ;fuckgfw.com/mp3k18/a2/1429_9466.mp3  
[2013-09-06 08:57:01] 2453888 group6/M00/00/2D/Kj4ZKlIpKL6AOkQ-ACVxgMD1aRE474.mp3 ;fuckgfw.com/mp3k18/a2/1429_9460.mp3  
[2013-09-06 08:58:00] 1375232 group14/M00/00/0C/Kj4ZLVIpKPqAFmmkABT8AAoz9lU552.mp3 ;fuckgfw.com/mp3k18/a2/1487_10243.mp3  
[2013-09-06 08:58:01] 3095808 group14/M00/00/0F/Kj4ZLFIpKPqAC73LAC89ACy9iyo432.mp3 ;fuckgfw.com/mp3k18/a2/1470_10017.mp3  
[2013-09-06 08:58:01] 2378240 group14/M00/00/0F/Kj4ZLFIpKPqADabyACRKANFt20E358.mp3 ;fuckgfw.com/mp3k18/a2/1471_10021.mp3  
[2013-09-06 08:58:01] 2102144 group14/M00/00/0C/Kj4ZLVIpKPqAOF32ACATgJsIdR0090.mp3 ;fuckgfw.com/mp3k18/a2/1465_9961.mp3  
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>bash中while循环的一个大坑</title>
      <link>https://pureage.info/2013/08/22/122.html</link>
      <pubDate>Thu, 22 Aug 2013 03:06:00 +0000</pubDate>
      
      <guid>https://pureage.info/2013/08/22/122.html</guid>
      <description>&lt;p&gt;起因是这样的，在一个常规的日志处理脚本中，最普通不过的while read line;do XXXX;done&amp;lt;file的应用场景。可是发现文件处理完后，该脚本并没有停止，仍在不停执行，准确点说，是死循环了。第一反应是想到是不是文件格式问题，导致在判断文件结束上出现了问题？但所有的文件都是在服务器上直接生成或创建的，不会存在这个问题。脚本通读了几遍，未果；无奈之下，只好祭出bash -x来。才发现，原来是在敲脚本时，不知怎么手抖了一下，在while和do语句之间，打上了个echo语句。这个就是罪魁祸首了，删掉后，脚本就恢复正常了。&lt;/p&gt;
&lt;p&gt;如果就这么过去了，多没意思，我觉得有必要深究一下while的运行机制。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sort命令中-k、-t选项的用法</title>
      <link>https://pureage.info/2013/08/05/120.html</link>
      <pubDate>Mon, 05 Aug 2013 12:56:00 +0000</pubDate>
      
      <guid>https://pureage.info/2013/08/05/120.html</guid>
      <description>&lt;h1 id=&#34;需求&#34;&gt;需求：&lt;/h1&gt;
&lt;p&gt;假设有个result_test_upload.log的文件，里面存放着一些FastDFS系统中的fileid。文本内容如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;group1/M00/04/08/wKhwglHq1rqAYO2oAAAoAChSBpE0502682  
group2/M00/05/06/wKhwglHq2CGAIs8AAAAoAChSBpE9287977  
......(略）......  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如何统计出分配到每个group的文件的总和并将其按group1，group2，group3的顺序列出来，以方便观察是否所有的fileid均匀的分配到FastDFS的group中？&lt;/p&gt;
&lt;h1 id=&#34;方法&#34;&gt;方法：&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;cat result_test_upload.log  | grep -o group[0-9][0-9]*  | sort -n -t p -k 2| uniq -c  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，grep -o group-0-9][0-9].*已经把每个group名截取出来了，sort -t p 表示以p为分隔，-k 2 表示按以p为分隔的第二个域来排序，也就是group1,group2,group3&amp;hellip;中的1,2,3.   sort -n很简单，表示按照group1,group2,group3&amp;hellip;groupn的顺序排列。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>bash下如何实现perl中seek的功能？</title>
      <link>https://pureage.info/2013/07/21/119.html</link>
      <pubDate>Sun, 21 Jul 2013 15:23:00 +0000</pubDate>
      
      <guid>https://pureage.info/2013/07/21/119.html</guid>
      <description>&lt;p&gt;因为日志处理需要，接触到perl,虽然还未入门，但通过几个函数就可以发现其在文本处理上的威力确实名不虚传，更不用提正则表达式了。&lt;/p&gt;
&lt;p&gt;假设有这样的应用场景：客户通过ftp客户端上传文件到接入端ftp服务器，接入端ftp服务器作为分布式存储系统的客户端，再将这些文件存入到后面的分布式存储服务器中。这个接入端ftp服务器要做的工作就是定时分析ftp server（假设是vsftpd,则日志为xferlog)的日志来获取客户上传的文件，再对这些文件做后续处理。客户上传时随时进行的，xferlog的记录条数也随之增长。&lt;/p&gt;
&lt;p&gt;perl中通过seek函数可以很方便的做到，每一次脚本执行时，都将上一次脚本执行时xferlog的大小作为本次读操作的偏移量，用这个偏移量来调用seek，本次处理完后再将该偏移量更新后存入到一个文件供下次脚本执行时读取。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>记一个here document的坑</title>
      <link>https://pureage.info/2013/05/24/115.html</link>
      <pubDate>Thu, 23 May 2013 16:49:00 +0000</pubDate>
      
      <guid>https://pureage.info/2013/05/24/115.html</guid>
      <description>&lt;h1 id=&#34;1here-document&#34;&gt;1.here document&lt;/h1&gt;
&lt;p&gt;here document经常用于一些需要交互性输入指令的程序中，例如登陆ftp。例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ftp -n $HOST &amp;lt;&amp;lt;EOF
quote USER $USER  
quote PASS $PASS  
binary  
put $FileName  
quit  
EOF  
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;2踩到的坑&#34;&gt;2.踩到的坑&lt;/h1&gt;
&lt;p&gt;在工作中，涉及到很多对redis的操作，先简单的用shell脚本实现了一下。大概流程是这样的：shell脚本调用C语言程序，根据C程序的输出，来操作redis。因此主要涉及两件事：shell脚本获取C程序输出，shell脚本用here document操作redis。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>shell on 纯真年代</title>
    <link>https://pureage.info/tags/shell/</link>
    <description>Recent content in shell on 纯真年代</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 30 Apr 2014 15:43:00 +0000</lastBuildDate><atom:link href="https://pureage.info/tags/shell/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>RPM 中的 %config 和 %config(noreplace)</title>
      <link>https://pureage.info/2014/04/30/noreplace-in-rpm-spec-file.html</link>
      <pubDate>Wed, 30 Apr 2014 15:43:00 +0000</pubDate>
      
      <guid>https://pureage.info/2014/04/30/noreplace-in-rpm-spec-file.html</guid>
      <description>&lt;p&gt;打开一个 rpm spec 文件，在 &lt;code&gt;%files&lt;/code&gt; 段有一个指令很常见：&lt;code&gt;%config(noreplace)&lt;/code&gt;，这个指定到底是干什么用的呢？&lt;/p&gt;
&lt;p&gt;答案是，该指令决定如果一个文件被管理员修改过后，下次更新该文件所在的rpm包时，该文件的存在状态。例如，一般升级软件时，配置文件是不会变化的，而主程序则一般需要被升级（替换）。&lt;/p&gt;
&lt;p&gt;对于 spec 文件中在 &lt;code&gt;%files&lt;/code&gt; 段的某一个文件，我们要讨论三种情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;没有带 &lt;code&gt;%config&lt;/code&gt; 指令。例如：&lt;code&gt;%{_sbindir}/redis-server&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;带了 &lt;code&gt;%congfig&lt;/code&gt; 指令。例如：&lt;code&gt;%config %{_sysconfdir}/redis/redis.conf&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;带了 &lt;code&gt;%config(noreplace)&lt;/code&gt; 指令。例如：&lt;code&gt;%config(noreplace) %{_sysconfdir}/redis/redis.conf&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>依赖一个 RPM 来制作新的 RPM</title>
      <link>https://pureage.info/2014/01/27/176.html</link>
      <pubDate>Mon, 27 Jan 2014 03:41:46 +0000</pubDate>
      
      <guid>https://pureage.info/2014/01/27/176.html</guid>
      <description>&lt;p&gt;项目中有这样一个场景：A 软件通过 rpm 包发布，B 软件严重依赖 A 软件，但在它的基础上有一些业务逻辑的添加和修改。A 软件是公司一个历史悠久的产品，且保持频繁的更新，B 软件是我在维护。&lt;/p&gt;
&lt;p&gt;在开发的时候，很简单，先把某一个稳定版本的 A 软件安装到开发机上，然后直接进行业务逻辑的开发就可以了。但在发布的时候肯定就不能这么做了，你很难要求运维先去发布服务器上下载一个 A 软件的 rpm 包，安装或更新完后，再去发布服务器上下载一个 B 软件的业务逻辑包，再进行相关的配置。所以，我需要做出一个 B 软件的独立的 rpm 包，用这个 rpm 包安装或更新后，直接能进行相关的配置。&lt;/p&gt;
&lt;p&gt;再来澄清一下需求：B 软件既要严重依赖 A 软件，但要在 A 软件上添加很多业务逻辑。但要求在发布的时候脱离对 A 软件 rpm 包的依赖。&lt;/p&gt;
&lt;p&gt;最简单的方法，当然是先把 A 软件的代码库做一个分支，或者拷贝出一个新的代码库，在上面进行开发，将 B 软件与 A 软件独立开来。这样发布的时候当然就是一个独立的包了。但如前所属，A 软件更新频繁，生命力旺盛，我可不想时时来在同步上花时间。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>利用 here document 携带 c 代码</title>
      <link>https://pureage.info/2013/10/08/129.html</link>
      <pubDate>Tue, 08 Oct 2013 03:23:00 +0000</pubDate>
      
      <guid>https://pureage.info/2013/10/08/129.html</guid>
      <description>假设你想通过一段脚本调用 make 来编译代码，并且在脚本中将一些编译需要的系统信息传递给 makefile，可以通过 bash 的 here document 来实现。例如： tmp_src_filename=fdfs_check_bits.c cat &amp;lt;&amp;lt;EOF &amp;gt; $tmp_src_filename #include</description>
    </item>
    
    <item>
      <title>emlog 的一键备份</title>
      <link>https://pureage.info/2013/10/01/128.html</link>
      <pubDate>Tue, 01 Oct 2013 03:31:00 +0000</pubDate>
      
      <guid>https://pureage.info/2013/10/01/128.html</guid>
      <description>&lt;p&gt;对于一个托管在 LAMP 虚拟主机（不是 vps）环境下的 emlog 博客，不知道大家平时备份是不是和我一样这么操作的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;登陆到后台，备份数据库（当然，或者是用插件定期备份发送到邮箱）&lt;/li&gt;
&lt;li&gt;用 ftp 备份 content 目录&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果你想简化操作，下面的脚本也许可以帮到你。脚本很丑陋，能完成功能即可。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>漫谈 logrotate 与 crond</title>
      <link>https://pureage.info/2013/09/10/127.html</link>
      <pubDate>Tue, 10 Sep 2013 15:11:00 +0000</pubDate>
      
      <guid>https://pureage.info/2013/09/10/127.html</guid>
      <description>&lt;h2 id=&#34;什么是-logrotate&#34;&gt;什么是 logrotate&lt;/h2&gt;
&lt;p&gt;logrotate 是一款用来切割日志的工具，更确切的说，是切割文本的工具，但通常用在软件日志切割上。为什么要进行日志切割呢？原因可以有很多，最明显的一个就是防止日志文件变得太大。&lt;/p&gt;
&lt;h2 id=&#34;lorotate的切割方式&#34;&gt;lorotate的切割方式&lt;/h2&gt;
&lt;p&gt;以 Nginx 为例，假设其错误日志放在 /data/proclog/log/nginx/ 下，名为 nginx_error.log，当 logrotate 运行时，如果满足切割要求了，则会将 nginx_error.log 改名为 nginx_error.log.1，并重新创建一个新的空文件 nginx_error.log 作为新的错误日志。&lt;/p&gt;
&lt;p&gt;当进行其二次切割时，nginx_error.log.1 被改名为 nginx_error.log.2，刚才创建的 nginx_error.log 被改名为新的 nginx_error.log.1，然后再次重新创建一个新的空文件 nginx_error.log 作为新的错误日志投入使用。&lt;/p&gt;
&lt;p&gt;当进行第三次切割时，nginx_error.log.2 变为 nginx_error.log.3，nginx_error.log.1 变为nginx_error.log.2，nginx_error.log 变为 nginx_error.log.1，一个新的 nginx_error.log 被再次创建。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>uniq、sort 不得不注意的尾部空格（trailing whitespaces)</title>
      <link>https://pureage.info/2013/09/09/126.html</link>
      <pubDate>Mon, 09 Sep 2013 13:38:00 +0000</pubDate>
      
      <guid>https://pureage.info/2013/09/09/126.html</guid>
      <description>&lt;h2 id=&#34;问题产生背景&#34;&gt;问题产生背景&lt;/h2&gt;
&lt;p&gt;自己写的一个基于 FastDFS 的客户端程序的日志格式如下：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;[2013-09-06 08:57:01] 1884096 group6/M00/00/2D/Kj4ZKlIpKL6Actm8ABy_wPYwpa8782.mp3 ;fuckgfw.com/mp3k18/a2/1375_8767.mp3  
[2013-09-06 08:57:01] 1932032 group6/M00/00/2D/Kj4ZKlIpKL6APMlMAB17AFl-Zaw344.mp3 ;fuckgfw.com/mp3k18/a2/1390_20402.mp3
[2013-09-06 08:57:01] 2115392 group6/M00/00/28/Kj4ZK1IpKL6AUW6WACBHQHAveu0805.mp3 ;fuckgfw.com/mp3k18/a2/1381_8842.mp3  
[2013-09-06 08:57:01] 2340800 group6/M00/00/28/Kj4ZK1IpKL-ABGh8ACO3wLWZNXA955.mp3 ;fuckgfw.com/mp3k18/a2/1395_9009.mp3  
[2013-09-06 08:57:01] 1734272 group6/M00/00/28/Kj4ZK1IpKL-AZF8OABp2gDqh-sA949.mp3 ;fuckgfw.com/mp3k18/a2/1429_9466.mp3  
[2013-09-06 08:57:01] 2453888 group6/M00/00/2D/Kj4ZKlIpKL6AOkQ-ACVxgMD1aRE474.mp3 ;fuckgfw.com/mp3k18/a2/1429_9460.mp3  
[2013-09-06 08:58:00] 1375232 group14/M00/00/0C/Kj4ZLVIpKPqAFmmkABT8AAoz9lU552.mp3 ;fuckgfw.com/mp3k18/a2/1487_10243.mp3  
[2013-09-06 08:58:01] 3095808 group14/M00/00/0F/Kj4ZLFIpKPqAC73LAC89ACy9iyo432.mp3 ;fuckgfw.com/mp3k18/a2/1470_10017.mp3  
[2013-09-06 08:58:01] 2378240 group14/M00/00/0F/Kj4ZLFIpKPqADabyACRKANFt20E358.mp3 ;fuckgfw.com/mp3k18/a2/1471_10021.mp3  
[2013-09-06 08:58:01] 2102144 group14/M00/00/0C/Kj4ZLVIpKPqAOF32ACATgJsIdR0090.mp3 ;fuckgfw.com/mp3k18/a2/1465_9961.mp3  
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>bash 中 while 循环的一个大坑</title>
      <link>https://pureage.info/2013/08/22/122.html</link>
      <pubDate>Thu, 22 Aug 2013 03:06:00 +0000</pubDate>
      
      <guid>https://pureage.info/2013/08/22/122.html</guid>
      <description>&lt;p&gt;起因是这样的，我有一个常规的日志处理脚本，是最普通不过的 &lt;code&gt;while read line;do XXXX;done&amp;lt;file&lt;/code&gt; 的应用场景。可是发现文件处理完后，该脚本并没有停止，仍在不停执行，准确点说，是死循环了。第一反应是想到是不是文件格式问题，导致在判断文件结束上出现了问题？但所有的文件都是在服务器上直接生成或创建的，不会存在这个问题。脚本通读了几遍，未果；无奈之下，只好祭出 bash -x 来。才发现，原来是在敲脚本时，不知怎么手抖了一下，在 while 和 do 语句之间，打上了个 echo 语句。这个就是罪魁祸首了，删掉后，脚本就恢复正常了。&lt;/p&gt;
&lt;p&gt;如果就这么过去了，多没意思，我觉得有必要深究一下 while 的运行机制。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sort 命令中 -k、-t 选项的用法</title>
      <link>https://pureage.info/2013/08/05/120.html</link>
      <pubDate>Mon, 05 Aug 2013 12:56:00 +0000</pubDate>
      
      <guid>https://pureage.info/2013/08/05/120.html</guid>
      <description>&lt;h2 id=&#34;需求&#34;&gt;需求&lt;/h2&gt;
&lt;p&gt;假设有个 result_test_upload.log 的文件，里面存放着一些 FastDFS 系统中的 fileid。文本内容如下：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;group1/M00/04/08/wKhwglHq1rqAYO2oAAAoAChSBpE0502682  
group2/M00/05/06/wKhwglHq2CGAIs8AAAAoAChSBpE9287977  
......(略）......  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如何统计出分配到每个 group 的文件的总和并将其按 group1、group2、group3 的顺序列出来，以方便观察是否所有的 fileid 均匀的分配到 FastDFS 的 group 中？&lt;/p&gt;
&lt;h2 id=&#34;方法&#34;&gt;方法&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cat result_test_upload.log  | grep -o group&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0-9&lt;span style=&#34;color:#f92672&#34;&gt;][&lt;/span&gt;0-9&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;*  | sort -n -t p -k 2| uniq -c  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中，&lt;code&gt;grep -o group-0-9][0-9].*&lt;/code&gt; 已经把每个 group 名截取出来了，&lt;code&gt;sort -t p&lt;/code&gt; 表示以 p 为分隔，&lt;code&gt;-k 2&lt;/code&gt; 表示按以 p 为分隔的第二个域来排序，也就是 group1、group2、group3&amp;hellip;中的1、2、3。-n 选项则很简单，表示按照group1、group2、group3&amp;hellip;groupn 的顺序排列。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>bash 下如何实现 perl 中 seek 的功能？</title>
      <link>https://pureage.info/2013/07/21/119.html</link>
      <pubDate>Sun, 21 Jul 2013 15:23:00 +0000</pubDate>
      
      <guid>https://pureage.info/2013/07/21/119.html</guid>
      <description>&lt;p&gt;因为日志处理需要，接触到 perl，虽然还未入门，但通过几个函数就可以发现其在文本处理上的威力确实名不虚传，更不用提正则表达式了。&lt;/p&gt;
&lt;p&gt;假设有这样的应用场景：客户通过 ftp 客户端上传文件到接入端 ftp 服务器，接入端 ftp 服务器作为分布式存储系统的客户端，再将这些文件存入到后面的分布式存储服务器中。这个接入端 ftp 服务器要做的工作就是定时分析 ftp server（假设是 vsftpd，日志为 xferlog）的日志来获取客户上传的文件，再对这些文件做后续处理。客户上传时随时进行的，xferlog 的记录条数也随之增长。&lt;/p&gt;
&lt;p&gt;perl 中通过 seek 函数可以很方便的做到，每一次脚本执行时，都将上一次脚本执行时 xferlog 的大小作为本次读操作的偏移量，用这个偏移量来调用 seek，本次处理完后再将该偏移量更新后存入到一个文件供下次脚本执行时读取。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>记一个 here document 的坑</title>
      <link>https://pureage.info/2013/05/24/115.html</link>
      <pubDate>Thu, 23 May 2013 16:49:00 +0000</pubDate>
      
      <guid>https://pureage.info/2013/05/24/115.html</guid>
      <description>&lt;h2 id=&#34;1-here-document&#34;&gt;1. here document&lt;/h2&gt;
&lt;p&gt;在 bash 中，here document 经常用于一些需要交互性输入指令的程序中，例如登陆 ftp。例如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ftp -n $HOST &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;lt;&amp;lt;EOF
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;quote USER $USER  
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;quote PASS $PASS  
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;binary  
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;put $FileName  
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;quit  
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;EOF&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;2-踩到的坑&#34;&gt;2. 踩到的坑&lt;/h2&gt;
&lt;p&gt;在工作中，涉及到很多对 redis 的操作，先简单的用 shell 脚本实现了一下。大概流程是这样的：shell 脚本调用 C 语言程序，根据 C 程序的输出，来操作 redis。因此主要涉及两件事：shell 脚本获取 C 程序输出，shell 脚本用 here document 操作 redis。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
